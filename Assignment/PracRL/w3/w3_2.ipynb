{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w3.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gVKlzMbll1z"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDcQj4jEll11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28feb34-54fa-48ee-9087-685c89749107"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGA-4nhAll11"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq_k4Cogll12"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN9Xhgbfll12"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = self.get_qvalue(state, possible_actions[0])\n",
        "        \n",
        "        for i in possible_actions :\n",
        "          value = max(value, self.get_qvalue(state, possible_actions[i]))\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        Q_hat = reward + gamma * self.get_value(next_state)\n",
        "\n",
        "        self.set_qvalue(state, action, (1 - learning_rate)*self.get_qvalue(state, action) + learning_rate*Q_hat)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        q_list = []\n",
        "        for i in possible_actions :\n",
        "          q_list.append(self.get_qvalue(state, possible_actions[i]))\n",
        "\n",
        "        q_list = np.array(q_list)\n",
        "        best_action = possible_actions[np.argmax(q_list)]\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.get_best_action).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        rnd = random.uniform(0, 1)\n",
        "        if rnd < epsilon:\n",
        "          return random.choice(possible_actions)\n",
        "        else :\n",
        "          return self.get_best_action(state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-VkZrFUll13"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gijexJAnll13"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        l = len(possible_actions)\n",
        "        if l == 0:\n",
        "            return 0.0\n",
        "        \n",
        "        state_value = 0\n",
        "        best_action = self.get_best_action(state)\n",
        "        for i in possible_actions:\n",
        "          if i == best_action:\n",
        "            state_value = state_value + ((1 - epsilon) + epsilon/l)*self.get_qvalue(state, i)\n",
        "          else:\n",
        "            state_value += (epsilon/l)*self.get_qvalue(state, i)\n",
        "        \n",
        "\n",
        "        return state_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE7617-dll14"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce5HSve2ll14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821d5a49-93f9-46f6-ecd1-a6ab8ab64e1f"
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C8gNadwll14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9c69ae-512b-42ca-9977-a521483d4d0d"
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seVyJ0Nmll15"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAOIi8COll15"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIyo66ESll15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "500193a9-eda8-4c82-ccc4-f1332ffc6d05"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVSARSA mean reward = -27.58\n",
            "QLEARNING mean reward = -89.12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ2hcioLll15"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZHAFclkll16"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AzB7zAUll16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a86869b-fd16-46d8-88bd-31b2c01864c4"
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-Learning\n",
            " v  v  v  >  >  >  v  >  v  >  v  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRFlAC5Jll16"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}